#!/usr/bin/env python3

"""
çµ±åˆãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚·ã‚¹ãƒ†ãƒ 
å…¨ãƒšã‚¤ãƒ³ã®é€²æ—ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã€çµ±åˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
"""

import json
import os
import subprocess
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional


class MetricsCollector:
    """çµ±åˆãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, project_root: str = "/mnt/e/MicrosoftProductManagementTools"):
        self.project_root = Path(project_root)
        self.reports_dir = self.project_root / "reports" / "progress"
        self.logs_dir = self.project_root / "logs"
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.reports_dir.mkdir(parents=True, exist_ok=True)
        self.logs_dir.mkdir(parents=True, exist_ok=True)
    
    def log(self, message: str, level: str = "INFO"):
        """ãƒ­ã‚°å‡ºåŠ›"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_entry = f"[{timestamp}] {level}: {message}"
        
        print(log_entry)
        
        with open(self.logs_dir / "metrics_collector.log", "a") as f:
            f.write(log_entry + "\n")
    
    def collect_devops_metrics(self) -> Dict:
        """DevOpsãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
        self.log("Collecting DevOps metrics...")
        
        try:
            # DevOpsç›£è¦–ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
            result = subprocess.run(
                [str(self.project_root / "scripts" / "automation" / "devops_monitor.sh")],
                capture_output=True,
                text=True,
                cwd=str(self.project_root)
            )
            
            if result.returncode == 0:
                self.log("DevOps monitoring script executed successfully")
                
                # ç”Ÿæˆã•ã‚ŒãŸJSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
                devops_json = self.reports_dir / "devops_status.json"
                if devops_json.exists():
                    with open(devops_json, 'r') as f:
                        return json.load(f)
            else:
                self.log(f"DevOps script failed: {result.stderr}", "ERROR")
                
        except Exception as e:
            self.log(f"Error collecting DevOps metrics: {e}", "ERROR")
        
        return self.get_default_devops_metrics()
    
    def get_default_devops_metrics(self) -> Dict:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®DevOpsãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
        return {
            "timestamp": datetime.now().isoformat(),
            "developer": "devops",
            "infrastructure_metrics": {
                "ci_pipeline_status": "unknown",
                "docker_build_success_rate": "N/A",
                "deployment_readiness": "checking",
                "tmux_environment_health": "unknown"
            },
            "automation_status": {
                "cron_jobs_active": 0,
                "monitoring_scripts": "initializing",
                "alert_system": "configuring"
            }
        }
    
    def collect_test_metrics(self) -> Dict:
        """ãƒ†ã‚¹ãƒˆãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
        self.log("Collecting test metrics...")
        
        try:
            # pytestå®Ÿè¡Œ
            result = subprocess.run(
                ["python", "-m", "pytest", "--tb=short", "--json-report", "--json-report-file=test_report.json"],
                capture_output=True,
                text=True,
                cwd=str(self.project_root)
            )
            
            test_report_path = self.project_root / "test_report.json"
            if test_report_path.exists():
                with open(test_report_path, 'r') as f:
                    pytest_data = json.load(f)
                
                return {
                    "timestamp": datetime.now().isoformat(),
                    "developer": "tester",
                    "test_results": {
                        "total_tests": pytest_data.get("summary", {}).get("total", 0),
                        "passed": pytest_data.get("summary", {}).get("passed", 0),
                        "failed": pytest_data.get("summary", {}).get("failed", 0),
                        "coverage_percentage": self.get_coverage_percentage()
                    }
                }
            
        except Exception as e:
            self.log(f"Error collecting test metrics: {e}", "ERROR")
        
        return self.get_default_test_metrics()
    
    def get_coverage_percentage(self) -> float:
        """ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡å–å¾—"""
        try:
            coverage_json = self.project_root / "coverage.json"
            if coverage_json.exists():
                with open(coverage_json, 'r') as f:
                    coverage_data = json.load(f)
                return coverage_data.get("totals", {}).get("percent_covered", 0.0)
        except Exception as e:
            self.log(f"Error reading coverage data: {e}", "ERROR")
        
        return 0.0
    
    def get_default_test_metrics(self) -> Dict:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ†ã‚¹ãƒˆãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
        return {
            "timestamp": datetime.now().isoformat(),
            "developer": "tester",
            "test_results": {
                "total_tests": 0,
                "passed": 0,
                "failed": 0,
                "coverage_percentage": 0.0
            }
        }
    
    def collect_backend_metrics(self) -> Dict:
        """ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
        self.log("Collecting backend metrics...")
        
        # API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        api_dir = self.project_root / "src" / "api"
        endpoint_count = 0
        
        if api_dir.exists():
            for py_file in api_dir.rglob("*.py"):
                if py_file.name != "__init__.py":
                    endpoint_count += 1
        
        return {
            "timestamp": datetime.now().isoformat(),
            "developer": "backend",
            "metrics": {
                "api_endpoints_completed": endpoint_count,
                "test_coverage": self.get_coverage_percentage(),
                "graph_api_integration": "in_progress",
                "powershell_bridge_status": "planning"
            }
        }
    
    def collect_frontend_metrics(self) -> Dict:
        """ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
        self.log("Collecting frontend metrics...")
        
        # GUIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        gui_dir = self.project_root / "src" / "gui"
        component_count = 0
        
        if gui_dir.exists():
            for py_file in gui_dir.rglob("*.py"):
                if py_file.name != "__init__.py":
                    component_count += 1
        
        return {
            "timestamp": datetime.now().isoformat(),
            "developer": "frontend",
            "metrics": {
                "gui_components_completed": component_count,
                "pyqt6_coverage": 0.0,  # å®Ÿè£…æ™‚ã«è¨ˆç®—
                "ui_consistency_score": 85.0
            }
        }
    
    def generate_integrated_report(self, all_metrics: Dict) -> str:
        """çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        self.log("Generating integrated report...")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = self.reports_dir / f"integrated_report_{timestamp}.json"
        
        # çµ±åˆãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿
        integrated_data = {
            "report_timestamp": datetime.now().isoformat(),
            "project_name": "Microsoft365 Management Tools - Python Migration",
            "overall_status": self.calculate_overall_status(all_metrics),
            "metrics": all_metrics
        }
        
        # JSONãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        with open(report_path, 'w') as f:
            json.dump(integrated_data, f, indent=2)
        
        self.log(f"Integrated report saved: {report_path}")
        
        # HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        html_report = self.generate_html_report(integrated_data)
        html_path = self.reports_dir / f"integrated_report_{timestamp}.html"
        
        with open(html_path, 'w') as f:
            f.write(html_report)
        
        self.log(f"HTML report saved: {html_path}")
        
        return str(report_path)
    
    def calculate_overall_status(self, metrics: Dict) -> str:
        """å…¨ä½“ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¨ˆç®—"""
        total_coverage = 0
        coverage_count = 0
        
        for role, data in metrics.items():
            if "coverage" in str(data).lower():
                # ã‚«ãƒãƒ¬ãƒƒã‚¸æƒ…å ±ã‚’æŠ½å‡º
                if "test_coverage" in data.get("metrics", {}):
                    total_coverage += data["metrics"]["test_coverage"]
                    coverage_count += 1
        
        avg_coverage = total_coverage / coverage_count if coverage_count > 0 else 0
        
        if avg_coverage >= 90:
            return "excellent"
        elif avg_coverage >= 80:
            return "good"
        elif avg_coverage >= 70:
            return "acceptable"
        else:
            return "needs_improvement"
    
    def generate_html_report(self, data: Dict) -> str:
        """HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        return f"""<!DOCTYPE html>
<html>
<head>
    <title>Microsoft 365 Tools - Python Migration Progress Report</title>
    <meta charset="UTF-8">
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
        .header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 30px; border-radius: 8px; text-align: center; }}
        .metrics-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin-top: 20px; }}
        .metric-card {{ background: #f8f9fa; padding: 25px; border-radius: 8px; border-left: 4px solid #007bff; }}
        .status-excellent {{ color: #28a745; }}
        .status-good {{ color: #17a2b8; }}
        .status-acceptable {{ color: #ffc107; }}
        .status-needs-improvement {{ color: #dc3545; }}
        .progress-bar {{ width: 100%; height: 20px; background: #e9ecef; border-radius: 10px; margin: 10px 0; }}
        .progress-fill {{ height: 100%; background: linear-gradient(90deg, #28a745, #20c997); border-radius: 10px; transition: width 0.3s ease; }}
        .timestamp {{ font-size: 0.9em; color: #6c757d; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸš€ Microsoft 365 Tools - Python Migration Progress</h1>
            <p>Generated: {data['report_timestamp']}</p>
            <p class="status-{data['overall_status']}">Overall Status: {data['overall_status'].replace('_', ' ').title()}</p>
        </div>
        
        <div class="metrics-grid">
            <div class="metric-card">
                <h3>ğŸ—ï¸ DevOps Infrastructure</h3>
                <p>Pipeline Status: {data['metrics'].get('devops', {}).get('infrastructure_metrics', {}).get('ci_pipeline_status', 'Unknown')}</p>
                <p>Environment: {data['metrics'].get('devops', {}).get('infrastructure_metrics', {}).get('tmux_environment_health', 'Unknown')}</p>
                <p>Automation: {data['metrics'].get('devops', {}).get('automation_status', {}).get('monitoring_scripts', 'Unknown')}</p>
            </div>
            
            <div class="metric-card">
                <h3>ğŸ”§ Backend Development</h3>
                <p>API Endpoints: {data['metrics'].get('backend', {}).get('metrics', {}).get('api_endpoints_completed', 0)}</p>
                <p>Coverage: {data['metrics'].get('backend', {}).get('metrics', {}).get('test_coverage', 0):.1f}%</p>
                <div class="progress-bar">
                    <div class="progress-fill" style="width: {data['metrics'].get('backend', {}).get('metrics', {}).get('test_coverage', 0)}%"></div>
                </div>
            </div>
            
            <div class="metric-card">
                <h3>ğŸ¨ Frontend Development</h3>
                <p>GUI Components: {data['metrics'].get('frontend', {}).get('metrics', {}).get('gui_components_completed', 0)}</p>
                <p>UI Consistency: {data['metrics'].get('frontend', {}).get('metrics', {}).get('ui_consistency_score', 0):.1f}%</p>
                <div class="progress-bar">
                    <div class="progress-fill" style="width: {data['metrics'].get('frontend', {}).get('metrics', {}).get('ui_consistency_score', 0)}%"></div>
                </div>
            </div>
            
            <div class="metric-card">
                <h3>ğŸ§ª Quality Assurance</h3>
                <p>Total Tests: {data['metrics'].get('tester', {}).get('test_results', {}).get('total_tests', 0)}</p>
                <p>Passed: {data['metrics'].get('tester', {}).get('test_results', {}).get('passed', 0)}</p>
                <p>Coverage: {data['metrics'].get('tester', {}).get('test_results', {}).get('coverage_percentage', 0):.1f}%</p>
                <div class="progress-bar">
                    <div class="progress-fill" style="width: {data['metrics'].get('tester', {}).get('test_results', {}).get('coverage_percentage', 0)}%"></div>
                </div>
            </div>
        </div>
        
        <div class="timestamp">
            Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        </div>
    </div>
</body>
</html>"""
    
    def run_collection(self):
        """ãƒ¡ã‚¤ãƒ³åé›†å‡¦ç†"""
        self.log("Starting integrated metrics collection...")
        
        # å„å½¹å‰²ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
        all_metrics = {
            "devops": self.collect_devops_metrics(),
            "backend": self.collect_backend_metrics(),
            "frontend": self.collect_frontend_metrics(),
            "tester": self.collect_test_metrics()
        }
        
        # çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report_path = self.generate_integrated_report(all_metrics)
        
        self.log(f"Metrics collection completed. Report: {report_path}")
        
        return report_path


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    try:
        collector = MetricsCollector()
        report_path = collector.run_collection()
        
        print(f"âœ… Metrics collection completed successfully")
        print(f"ğŸ“Š Report saved to: {report_path}")
        
        return 0
        
    except Exception as e:
        print(f"âŒ Error during metrics collection: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())